{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"gi60YmV0K7xO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741127051427,"user_tz":360,"elapsed":159739,"user":{"displayName":"Andrew Castillo","userId":"02822267340440655112"}},"outputId":"9c96d24a-5419-4890-8e06-9c7e3a18dba1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Error processing 202503-divvy-tripdata.zip: 404 Client Error: Not Found for url: https://divvy-tripdata.s3.amazonaws.com/202503-divvy-tripdata.zip\n","Error processing 202504-divvy-tripdata.zip: 404 Client Error: Not Found for url: https://divvy-tripdata.s3.amazonaws.com/202504-divvy-tripdata.zip\n","Error processing 202505-divvy-tripdata.zip: 404 Client Error: Not Found for url: https://divvy-tripdata.s3.amazonaws.com/202505-divvy-tripdata.zip\n","Error processing 202506-divvy-tripdata.zip: 404 Client Error: Not Found for url: https://divvy-tripdata.s3.amazonaws.com/202506-divvy-tripdata.zip\n","Error processing 202507-divvy-tripdata.zip: 404 Client Error: Not Found for url: https://divvy-tripdata.s3.amazonaws.com/202507-divvy-tripdata.zip\n","Error processing 202508-divvy-tripdata.zip: 404 Client Error: Not Found for url: https://divvy-tripdata.s3.amazonaws.com/202508-divvy-tripdata.zip\n","Error processing 202509-divvy-tripdata.zip: 404 Client Error: Not Found for url: https://divvy-tripdata.s3.amazonaws.com/202509-divvy-tripdata.zipError processing 202510-divvy-tripdata.zip: 404 Client Error: Not Found for url: https://divvy-tripdata.s3.amazonaws.com/202510-divvy-tripdata.zip\n","\n","Error processing 202511-divvy-tripdata.zip: 404 Client Error: Not Found for url: https://divvy-tripdata.s3.amazonaws.com/202511-divvy-tripdata.zip\n","Error processing 202512-divvy-tripdata.zip: 404 Client Error: Not Found for url: https://divvy-tripdata.s3.amazonaws.com/202512-divvy-tripdata.zip\n"]}],"source":["import os\n","import requests\n","import zipfile\n","import pandas as pd\n","from io import BytesIO\n","from concurrent.futures import ThreadPoolExecutor\n","\n","# ✅ Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# ✅ Define the path to your Shared Drive\n","SHARED_DRIVE_NAME = \"Time Series\"\n","DATA_DIR = f\"/content/drive/Shared drives/{SHARED_DRIVE_NAME}/divvy_data/prod/overall\"\n","\n","# Ensure the directory exists\n","os.makedirs(DATA_DIR, exist_ok=True)\n","\n","BASE_URL = \"https://divvy-tripdata.s3.amazonaws.com/\"\n","YEARS = range(2020, 2026)  # Include 2020 in the processing\n","\n","# ✅ Function to download and extract data\n","def download_and_extract(year, month=None):\n","    \"\"\"Downloads and extracts Divvy data for a given year and month (or quarter for 2020 Q1).\"\"\"\n","\n","    # Special case for Q1 2020\n","    if year == 2020 and month is None:\n","        filename = \"Divvy_Trips_2020_Q1.zip\"\n","    else:\n","        filename = f\"{year}{month:02d}-divvy-tripdata.zip\"\n","\n","    file_url = f\"{BASE_URL}{filename}\"\n","\n","    try:\n","        response = requests.get(file_url, stream=True, timeout=10)\n","        response.raise_for_status()\n","\n","        with zipfile.ZipFile(BytesIO(response.content)) as z:\n","            # Get CSV filename inside ZIP\n","            csv_filename = z.namelist()[0]\n","            with z.open(csv_filename) as csvfile:\n","                df = pd.read_csv(csvfile, usecols=[\"ride_id\", \"rideable_type\", \"started_at\", \"start_station_id\"])\n","                df[\"date\"] = pd.to_datetime(df[\"started_at\"], errors=\"coerce\").dt.date\n","                return df\n","\n","    except Exception as e:\n","        print(f\"Error processing {filename}: {e}\")\n","        return None\n","\n","# ✅ Download and process data in parallel\n","all_data = []\n","with ThreadPoolExecutor(max_workers=10) as executor:\n","    futures = []\n","\n","    # Special case for Q1 2020\n","    futures.append(executor.submit(download_and_extract, 2020, None))\n","\n","    # Process monthly data from April 2020 - Dec 2025\n","    for year in YEARS:\n","        for month in range(1, 13):\n","            if year == 2020 and month <= 3:\n","                continue  # Skip Jan-Mar 2020 (already handled above)\n","            futures.append(executor.submit(download_and_extract, year, month))\n","\n","    for future in futures:\n","        result = future.result()\n","        if result is not None:\n","            all_data.append(result)\n","\n","# ✅ Load weather data\n","weather_df = pd.read_csv(\"/content/drive/Shared drives/Time Series/weather_data/daily_weather_forecast_chicago.csv\")\n","\n","# Ensure date is in datetime format for merging\n","weather_df[\"date\"] = pd.to_datetime(weather_df[\"time\"])\n","\n","weather_df = weather_df[[\"date\", \"temp_min_c\", \"rain_sum_mm\", \"snowfall_sum_cm\"]]\n","\n","# ✅ Compute e-bike ride proportion and merge weather data\n","if all_data:\n","    df_all = pd.concat(all_data, ignore_index=True)\n","\n","    # Identify e-bike rides\n","    df_all[\"is_ebike\"] = df_all[\"rideable_type\"] == \"electric_bike\"\n","\n","    # Compute unique e-bike rides separately\n","    ebike_rides = df_all[df_all[\"is_ebike\"]].groupby(\"date\")[\"ride_id\"].nunique()\n","\n","    # Aggregate unique ride counts per date\n","    grouped_df = df_all.groupby(\"date\").agg(\n","        total_rides=(\"ride_id\", \"nunique\"),\n","        stations=(\"start_station_id\", \"nunique\")\n","    ).reset_index()\n","\n","    # Merge e-bike rides back into main dataframe\n","    grouped_df = grouped_df.merge(ebike_rides.rename(\"ebike_rides\"), on=\"date\", how=\"left\").fillna(0)\n","\n","    # Station data, moving average & differencing\n","    grouped_df[\"stations_shift\"] = grouped_df[\"stations\"].shift(1)\n","    grouped_df[\"stations_ma365\"] = grouped_df[\"stations_shift\"].rolling(window=365, min_periods=1).mean()\n","    grouped_df[\"stations_ma30\"] = grouped_df[\"stations_shift\"].rolling(window=30, min_periods=1).mean()\n","    grouped_df = grouped_df.drop(columns=['stations'])\n","\n","    # Compute proportion of e-bike rides\n","    grouped_df[\"ebike_shift\"] = grouped_df[\"ebike_rides\"].shift(1)\n","    grouped_df[\"ebike_shift_proportion\"] = grouped_df[\"ebike_rides\"].shift(1) / grouped_df[\"total_rides\"].shift(1)\n","\n","    # Compute moving average of e-bike rides\n","    grouped_df[\"ebike_proportion_ma365\"] = grouped_df[\"ebike_shift_proportion\"].rolling(window=365, min_periods=1).mean()\n","    grouped_df[\"ebike_proportion_ma30\"] = grouped_df[\"ebike_shift_proportion\"].rolling(window=30, min_periods=1).mean()\n","    grouped_df = grouped_df.drop(columns=[\"ebike_rides\"])\n","\n","    # Ensure 'date' is in datetime format\n","    grouped_df[\"date\"] = pd.to_datetime(grouped_df[\"date\"])\n","\n","    # ✅ Merge with weather data\n","    grouped_df = grouped_df.merge(weather_df, on=\"date\", how=\"left\")\n"]},{"cell_type":"code","source":["def train_test_split_by_date(df, split_date=\"2024-01-01\"):\n","  data_raw = df.copy()\n","  train = data_raw[data_raw[\"date\"] < split_date]\n","  test = data_raw[data_raw[\"date\"] >= split_date]\n","  return train, test\n","\n","def add_date_features(df):\n","  data_raw = df.copy()\n","  data_raw[\"date\"] = pd.to_datetime(data_raw[\"date\"])\n","  data_raw.sort_values(\"date\",inplace=True)\n","  data_raw[\"month\"] = data_raw[\"date\"].dt.month\n","  data_raw[\"dayofweek\"] = data_raw[\"date\"].dt.dayofweek\n","  data_raw[\"year\"] = data_raw[\"date\"].dt.year\n","  return data_raw\n","\n","# Train Test split\n","train, test = train_test_split_by_date(grouped_df)\n","\n","# Extract date features\n","train = add_date_features(train)\n","test = add_date_features(test)\n","\n","train.to_csv(os.path.join(DATA_DIR, \"/content/drive/Shared drives/Time Series/divvy_data/prod/overall/divvy_train.csv\"), index=False)\n","test.to_csv(os.path.join(DATA_DIR, \"/content/drive/Shared drives/Time Series/divvy_data/prod/overall/divvy_test.csv\"), index=False)"],"metadata":{"id":"2jkkpEZokpzV","executionInfo":{"status":"ok","timestamp":1741127053057,"user_tz":360,"elapsed":1611,"user":{"displayName":"Andrew Castillo","userId":"02822267340440655112"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lNESmNpGRDDv"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}